{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Introduction to Neural Networks\n",
    "### Introduction to Matices & Dot Products\n",
    "\n",
    "1. We will practice with simple dot products of matrices\n",
    "1. Create and manipulate Vectors (arrays) and Matrices \n",
    "1. Practice with dot product and sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Vector is a 1D Shape - example is an ordered list of numbers\n",
    "# in Linear algebra it is useful to think of it as a single \"row\" or a single \"column\" of numbers\n",
    "A_Vector = np.array([10, 20, 30, 40])\n",
    "print(\"A_Vector:\\n\",A_Vector)\n",
    "# Element-wise multiplication\n",
    "print(\"A_Vector*2:\\n\",A_Vector*2)\n",
    "\n",
    "# Matrix is a 2D Shape - example is a table of numbers with rows and columns\n",
    "# Matrices are like stacks of \"row\" vectors\n",
    "\n",
    "# Operations on Vectors/Matrices\n",
    "# This matrix below has 2 rows and 4 columns\n",
    "A_Matrix = np.array([[1, 2, 3, 4],\n",
    "                     [5, 6, 7, 8]])\n",
    "print(\"A_Matrix:\\n\",A_Matrix)\n",
    "print(\"A_Matrix shape (rows, cols):\",A_Matrix.shape)\n",
    "\n",
    "# Let's Transpose the A_Matrix\n",
    "# Rows become Columns and Columns become Rows\n",
    "# note the .T operator for Transposing!\n",
    "A_Matrix_t = A_Matrix.T\n",
    "print(\"A_Matrix Transposed:\\n\",A_Matrix_t)\n",
    "print(\"A_Matrix Transposed shape (rows, cols):\",A_Matrix_t.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![m2](m1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# matrices and/or vectors have to have one matching \n",
    "# dimension to be multiplied (dot product) together\n",
    "# specifically the \"column\" dimension of the 1st matrix/vector \n",
    "# should be the same as \"row\" dimension of the 2nd matrix/vector\n",
    "# note the @ operator for dot product!\n",
    "mat_dot_product = A_Matrix @ A_Vector \n",
    "print(\"A @ B:\\n\",mat_dot_product)\n",
    "\n",
    "# The dimension of numpy objects can be accessed by .shape and\n",
    "# the .T operator takes the transpose (NxM to MxN)\n",
    "print(mat_dot_product, \"A_Matrix.shape:\",A_Matrix.shape, \"A_Vector.shape:\",A_Vector.shape, \"mat_dot_product.shape:\",mat_dot_product.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![dp1](dp1.png)\n",
    "![dp2](dp2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a numpy-style Matrix based on above picture\n",
    "# compute scalar product, scalar sum, and dot product of 2x2 and 2x2 matrix\n",
    "\n",
    "m1 = np.array([[1, 2],\n",
    "               [3, 4]])\n",
    "m2 = np.array([[5, 6],\n",
    "               [7, 8]])\n",
    "print(\"m1:\\n\",m1)  # matrix m1\n",
    "print(\"m2:\\n\",m2)  # matrix m2\n",
    "print(\"m1 * 3:\\n\",m1 * 3)  # Scalar product\n",
    "print(\"m1 + 10:\\n\",m1 + 10)  # Scalar sum\n",
    "print(\"m1 @ m2:\\n\",m1 @ m2) # dot product\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![s1](s1.png)\n",
    "![s2](s2.png)\n",
    "![s3](s3.png)\n",
    "![s4](s4.png)\n",
    "![s5](s5.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example forward propagation of a simple 3-layer neural network\n",
    "# see pictures above\n",
    "# start by computing dot product of 3x3 and 3x1 matrix of weights and inputs in input layer 1\n",
    "\n",
    "m3 = np.array([[.9,.3,.4],\n",
    "              [.2,.8,.2],\n",
    "              [.1,.5,.6]])\n",
    "print(\"Initial weights of Input Layer 1\\n\",m3)\n",
    "m4 = np.array([[.9],\n",
    "              [.1],\n",
    "              [.8]])\n",
    "print(\"Initial Inputs to the Input Layer 1\\n\",m4)             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![node2](node2.png)\n",
    "![sigm2](sigm2.png)\n",
    "![s6](s6.png)\n",
    "![s7](s7.png)\n",
    "![s8](s8.png)\n",
    "![s9](s9.png)\n",
    "![sten](s10.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example forward propagation of a simple 3-layer neural network continued\n",
    "def sigmoid(m,r,c):\n",
    "    res = np.empty_like(m)\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            res[i][j] = 1/(1+np.exp(-m[i][j]))\n",
    "    return res\n",
    "         \n",
    "print(\"Initial weights of Input Layer 1\\n\",m3) # from previous cell\n",
    "print(\"Initial Inputs to the Input Layer 1\\n\",m4) # from previous cell\n",
    "\n",
    "m5 = m3 @ m4 # m3 m4 from previous input layer 1\n",
    "print(\"sum(Weights * Initial Inputs) - the input to hidden layer 2\\n\",m5)\n",
    "m6 = sigmoid(m5,3,1)\n",
    "print(\"output from hidden layer 2 after sigmoid activation\\n\",m6)\n",
    "\n",
    "m7 = np.array([[.3,.7,.5],\n",
    "              [.6,.5,.2],\n",
    "              [.8,.1,.9]])\n",
    "print(\"Weights of the output layer 3\\n\",m7)\n",
    "m8 = m7 @ m6\n",
    "print(\"sum(Weights * Inputs from hidden layer 2) - the input to output layer 3\\n\",m8)\n",
    "m9 = sigmoid(m8,3,1)\n",
    "print(\"Final output from output layer 3 after sigmoid activation\\n\",m9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![node](node.png)\n",
    "![sigm](sigm.png)\n",
    "![exbias](exbias.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# An advanced example of forward propagation of a 3-layer neural network with biases applied\n",
    "# There are 2 inputs and 2 outputs\n",
    "# see pictures above\n",
    "# start by computing dot product of 2x2 and 2x1 matrix of weights and inputs in input layer 1\n",
    "def sigmoid(m,r,c):\n",
    "    res = np.empty_like(m)\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            res[i][j] = 1/(1+np.exp(-m[i][j]))\n",
    "    return res\n",
    "\n",
    "wn1 = np.array([[.3,-.4],\n",
    "              [.2,.6]]) \n",
    "bn1 = np.array([.25,.45]) # bias for hidden layer 1 nodes\n",
    "print(\"Initial weights of hidden Layer 1\\n\",wn1)\n",
    "in1 = np.array([[2],\n",
    "              [3]])\n",
    "print(\"Initial Inputs to the hidden Layer 1\\n\",in1)   \n",
    "\n",
    "sn1 = wn1 @ in1 + bn1.reshape((-1,1))  # dot product and add reshaped biases as column vector\n",
    "print(\"sum(Weights * Initial Inputs + Bias) - the input to hidden layer 2\\n\",sn1)\n",
    "on1 = sigmoid(sn1,2,1)\n",
    "print(\"output from hidden layer 2 after sigmoid activation\\n\",on1)\n",
    "\n",
    "in2 = on1  # input layer 2 = output layer 1\n",
    "wn2 = np.array([[.7,.5],\n",
    "              [-.3,-.1]])\n",
    "bn2 = np.array([.15,.35]) # bias for hidden layer 1 nodes\n",
    "print(\"Weights of the output layer 3\\n\",wn2)\n",
    "\n",
    "sn2 = wn2 @ in2 + bn2.reshape((-1,1))  # dot product and add reshaped biases as column vector\n",
    "print(\"sum(Weights * Inputs from hidden layer 2 + Bias) - the input to output layer 3\\n\",sn2)\n",
    "on2 = sigmoid(sn2,2,1)\n",
    "print(\"Final output from output layer 3 after sigmoid activation\\n\",on2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credits\n",
    "This notebook was modified from [Dr. Steve Brunton & Dr. Alan Kaptanoglu who teach the Mechanical Engineering Analysis course at the University of Washington](http://faculty.washington.edu/sbrunton/me564/). Thanks to the great folks at [Binder](https://mybinder.org/) and [Google Colaboratory](https://colab.research.google.com/notebooks/intro.ipynb) for making this notebook interactive without you needing to download it or install [Jupyter](https://jupyter.org/) on your own device. Find more activities and license info at [CODINGinK12.org](http://www.codingink12.org)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
